{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{alignat}{5}\n",
    "         & \\arg\\!\\min_{\\mathcal{D}, \\mathcal{R}} \\|X \\ -&\\mathcal{D}\\mathcal{R}\\|_F^2  + &\\lambda \\sum_{i=1}^k  \\|\\ r_i\\|_0     \\quad   \\\\\n",
    "         &\\text{s.t.}  \\quad  &\\|d_j\\|_2 \\leq 1&, \\forall j=1, ...,n  \\quad \n",
    "\\end{alignat}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\|X \\ -\\mathcal{D}\\mathcal{R}\\|_F^2 = \\|X - D_S D_S^+ X\\|_F^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random matrix (can be later an image for denoising!)\n",
    "d = 20\n",
    "K = 35\n",
    "n = 27\n",
    "\n",
    "X = np.random.uniform(low=-10, high=10, size=(d, K))\n",
    "D = np.random.uniform(low=-10, high=10, size=(d, n))\n",
    "\n",
    "# R will be n x K\n",
    "\n",
    "# normalize D s.t. that columns of D have l2 norm = 1\n",
    "for j in range(n):\n",
    "    D[:, j] /= np.sum(D[:, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.45270765,  23.41440318, -28.56850447, -26.74069234,\n",
       "        -8.20875057, -37.16254316,  15.2569892 ,  14.59582438,\n",
       "        21.94802464, -11.56327175, -51.79285997,  26.78503881,\n",
       "        28.84294399,  -2.43335045,  -2.48772689,  -1.94275794,\n",
       "        36.70833222,  30.4279479 , -14.23616006,  29.22736869,\n",
       "       -17.90881214,  29.18707895,   1.50316322, -23.34842022,\n",
       "       -16.16418047,  -5.19446365,  29.1235476 , -28.36961765,\n",
       "        13.55768383,  17.69889113,  18.40220582,  11.33449353,\n",
       "         1.70277477,  -4.52389701, -13.67604947])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 35)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\n",
      "[24, 0]\n",
      "[24, 0, 8]\n",
      "[24, 0, 8, 2]\n",
      "[24, 0, 8, 2, 14]\n",
      "[24, 0, 8, 2, 14, 7]\n",
      "[24, 0, 8, 2, 14, 7, 15]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10, 9]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10, 9, 20]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10, 9, 20, 19]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10, 9, 20, 19, 1]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10, 9, 20, 19, 1, 4]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10, 9, 20, 19, 1, 4, 25]\n",
      "[24, 0, 8, 2, 14, 7, 15, 26, 13, 6, 18, 3, 21, 5, 12, 17, 22, 10, 9, 20, 19, 1, 4, 25, 11]\n"
     ]
    }
   ],
   "source": [
    "# greedy algorithm\n",
    "num_steps = 25\n",
    "S = np.zeros(num_steps, dtype=int)\n",
    "val_trace = []\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    cur_sel_columns = list(S[:step])\n",
    "    # find argmin\n",
    "    norms = np.zeros(D.shape[1]) + 9999.9\n",
    "    for i in range(D.shape[1]):\n",
    "        if i in cur_sel_columns:\n",
    "            continue\n",
    "        DS = D[:, cur_sel_columns+[i]]\n",
    "        \n",
    "        norms[i] = np.linalg.norm(X - np.dot(DS, np.dot(np.linalg.pinv(DS), X)), 'fro')\n",
    "    S[step] = np.argmin(norms)\n",
    "    \n",
    "    # add current norm value for the current dict\n",
    "    cur_sel_columns = list(S[:step+1])\n",
    "    DS = D[:, cur_sel_columns]\n",
    "    obj_val = np.linalg.norm(X - np.dot(DS, np.dot(np.linalg.pinv(DS), X)), 'fro')\n",
    "    val_trace.append(obj_val)\n",
    "    print(cur_sel_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11718d7b8>]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEDCAYAAADZUdTgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a94438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(val_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 27)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lars\n",
    "from sklearn.utils.validation import check_array\n",
    "\n",
    "def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',\n",
    "                   regularization=None, copy_cov=True,\n",
    "                   init=None, max_iter=1000, check_input=True, verbose=0):\n",
    "    \"\"\"Generic sparse coding\n",
    "\n",
    "    Each column of the result is the solution to a Lasso problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array of shape (n_samples, n_features)\n",
    "        Data matrix.\n",
    "\n",
    "    dictionary: array of shape (n_components, n_features)\n",
    "        The dictionary matrix against which to solve the sparse coding of\n",
    "        the data. Some of the algorithms assume normalized rows.\n",
    "\n",
    "    gram: None | array, shape=(n_components, n_components)\n",
    "        Precomputed Gram matrix, dictionary * dictionary'\n",
    "        gram can be None if method is 'threshold'.\n",
    "\n",
    "    cov: array, shape=(n_components, n_samples)\n",
    "        Precomputed covariance, dictionary * X'\n",
    "\n",
    "    algorithm: {'lasso_lars', 'lasso_cd', 'lars', 'omp', 'threshold'}\n",
    "        lars: uses the least angle regression method (linear_model.lars_path)\n",
    "        lasso_lars: uses Lars to compute the Lasso solution\n",
    "        lasso_cd: uses the coordinate descent method to compute the\n",
    "        Lasso solution (linear_model.Lasso). lasso_lars will be faster if\n",
    "        the estimated components are sparse.\n",
    "        omp: uses orthogonal matching pursuit to estimate the sparse solution\n",
    "        threshold: squashes to zero all coefficients less than regularization\n",
    "        from the projection dictionary * data'\n",
    "\n",
    "    regularization : int | float\n",
    "        The regularization parameter. It corresponds to alpha when\n",
    "        algorithm is 'lasso_lars', 'lasso_cd' or 'threshold'.\n",
    "        Otherwise it corresponds to n_nonzero_coefs.\n",
    "\n",
    "    init: array of shape (n_samples, n_components)\n",
    "        Initialization value of the sparse code. Only used if\n",
    "        `algorithm='lasso_cd'`.\n",
    "\n",
    "    max_iter: int, 1000 by default\n",
    "        Maximum number of iterations to perform if `algorithm='lasso_cd'`.\n",
    "\n",
    "    copy_cov: boolean, optional\n",
    "        Whether to copy the precomputed covariance matrix; if False, it may be\n",
    "        overwritten.\n",
    "\n",
    "    check_input: boolean, optional\n",
    "        If False, the input arrays X and dictionary will not be checked.\n",
    "\n",
    "    verbose: int\n",
    "        Controls the verbosity; the higher, the more messages. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    code: array of shape (n_components, n_features)\n",
    "        The sparse codes\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.linear_model.lars_path\n",
    "    sklearn.linear_model.orthogonal_mp\n",
    "    sklearn.linear_model.Lasso\n",
    "    SparseCoder\n",
    "    \"\"\"\n",
    "    if X.ndim == 1:\n",
    "        X = X[:, np.newaxis]\n",
    "    n_samples, n_features = X.shape\n",
    "    if cov is None and algorithm != 'lasso_cd':\n",
    "        # overwriting cov is safe\n",
    "        copy_cov = False\n",
    "        cov = np.dot(dictionary, X.T)\n",
    "\n",
    "    if algorithm == 'lasso_lars':\n",
    "        alpha = float(regularization) / n_features  # account for scaling\n",
    "        try:\n",
    "            err_mgt = np.seterr(all='ignore')\n",
    "\n",
    "            # Not passing in verbose=max(0, verbose-1) because Lars.fit already\n",
    "            # corrects the verbosity level.\n",
    "            lasso_lars = LassoLars(alpha=alpha, fit_intercept=False,\n",
    "                                   verbose=verbose, normalize=False,\n",
    "                                   precompute=gram, fit_path=False)\n",
    "            lasso_lars.fit(dictionary.T, X.T, Xy=cov)\n",
    "            new_code = lasso_lars.coef_\n",
    "        finally:\n",
    "            np.seterr(**err_mgt)\n",
    "\n",
    "    elif algorithm == 'lasso_cd':\n",
    "        alpha = float(regularization) / n_features  # account for scaling\n",
    "\n",
    "        # TODO: Make verbosity argument for Lasso?\n",
    "        # sklearn.linear_model.coordinate_descent.enet_path has a verbosity\n",
    "        # argument that we could pass in from Lasso.\n",
    "        clf = Lasso(alpha=alpha, fit_intercept=False, normalize=False,\n",
    "                    precompute=gram, max_iter=max_iter, warm_start=True)\n",
    "        clf.coef_ = init\n",
    "        clf.fit(dictionary.T, X.T, check_input=check_input)\n",
    "        new_code = clf.coef_\n",
    "\n",
    "    elif algorithm == 'lars':\n",
    "        try:\n",
    "            err_mgt = np.seterr(all='ignore')\n",
    "\n",
    "            #hack\n",
    "            lars = Lars(fit_intercept=False, verbose=verbose, normalize=False,\n",
    "            precompute=gram, n_nonzero_coefs=int(regularization),\n",
    "            fit_path=True)\n",
    "            lars.fit(dictionary.T, X.T, Xy=cov)\n",
    "            new_code = lars.coef_\n",
    "            return np.array(new_code), lars.coef_path_\n",
    "            #hack end\n",
    "                \n",
    "            # Not passing in verbose=max(0, verbose-1) because Lars.fit already\n",
    "            # corrects the verbosity level.\n",
    "            lars = Lars(fit_intercept=False, verbose=verbose, normalize=False,\n",
    "                        precompute=gram, n_nonzero_coefs=int(regularization),\n",
    "                        fit_path=False)\n",
    "            lars.fit(dictionary.T, X.T, Xy=cov)\n",
    "            new_code = lars.coef_\n",
    "        finally:\n",
    "            np.seterr(**err_mgt)\n",
    "\n",
    "    elif algorithm == 'threshold':\n",
    "        new_code = ((np.sign(cov) *\n",
    "                    np.maximum(np.abs(cov) - regularization, 0)).T)\n",
    "\n",
    "    elif algorithm == 'omp':\n",
    "        # TODO: Should verbose argument be passed to this?\n",
    "        new_code = orthogonal_mp_gram(\n",
    "            Gram=gram, Xy=cov, n_nonzero_coefs=int(regularization),\n",
    "            tol=None, norms_squared=row_norms(X, squared=True),\n",
    "            copy_Xy=copy_cov).T\n",
    "    else:\n",
    "        raise ValueError('Sparse coding method must be \"lasso_lars\" '\n",
    "                         '\"lasso_cd\",  \"lasso\", \"threshold\" or \"omp\", got %s.'\n",
    "                         % algorithm)\n",
    "    return new_code\n",
    "\n",
    "\n",
    "# XXX : could be moved to the linear_model module\n",
    "def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',\n",
    "                  n_nonzero_coefs=None, alpha=None, copy_cov=True, init=None,\n",
    "                  max_iter=1000, n_jobs=1, check_input=True, verbose=0):\n",
    "    \"\"\"Sparse coding\n",
    "\n",
    "    Each row of the result is the solution to a sparse coding problem.\n",
    "    The goal is to find a sparse array `code` such that::\n",
    "\n",
    "        X ~= code * dictionary\n",
    "\n",
    "    Read more in the :ref:`User Guide <SparseCoder>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array of shape (n_samples, n_features)\n",
    "        Data matrix\n",
    "\n",
    "    dictionary: array of shape (n_components, n_features)\n",
    "        The dictionary matrix against which to solve the sparse coding of\n",
    "        the data. Some of the algorithms assume normalized rows for meaningful\n",
    "        output.\n",
    "\n",
    "    gram: array, shape=(n_components, n_components)\n",
    "        Precomputed Gram matrix, dictionary * dictionary'\n",
    "\n",
    "    cov: array, shape=(n_components, n_samples)\n",
    "        Precomputed covariance, dictionary' * X\n",
    "\n",
    "    algorithm: {'lasso_lars', 'lasso_cd', 'lars', 'omp', 'threshold'}\n",
    "        lars: uses the least angle regression method (linear_model.lars_path)\n",
    "        lasso_lars: uses Lars to compute the Lasso solution\n",
    "        lasso_cd: uses the coordinate descent method to compute the\n",
    "        Lasso solution (linear_model.Lasso). lasso_lars will be faster if\n",
    "        the estimated components are sparse.\n",
    "        omp: uses orthogonal matching pursuit to estimate the sparse solution\n",
    "        threshold: squashes to zero all coefficients less than alpha from\n",
    "        the projection dictionary * X'\n",
    "\n",
    "    n_nonzero_coefs: int, 0.1 * n_features by default\n",
    "        Number of nonzero coefficients to target in each column of the\n",
    "        solution. This is only used by `algorithm='lars'` and `algorithm='omp'`\n",
    "        and is overridden by `alpha` in the `omp` case.\n",
    "\n",
    "    alpha: float, 1. by default\n",
    "        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the\n",
    "        penalty applied to the L1 norm.\n",
    "        If `algorithm='threhold'`, `alpha` is the absolute value of the\n",
    "        threshold below which coefficients will be squashed to zero.\n",
    "        If `algorithm='omp'`, `alpha` is the tolerance parameter: the value of\n",
    "        the reconstruction error targeted. In this case, it overrides\n",
    "        `n_nonzero_coefs`.\n",
    "\n",
    "    init: array of shape (n_samples, n_components)\n",
    "        Initialization value of the sparse codes. Only used if\n",
    "        `algorithm='lasso_cd'`.\n",
    "\n",
    "    max_iter: int, 1000 by default\n",
    "        Maximum number of iterations to perform if `algorithm='lasso_cd'`.\n",
    "\n",
    "    copy_cov: boolean, optional\n",
    "        Whether to copy the precomputed covariance matrix; if False, it may be\n",
    "        overwritten.\n",
    "\n",
    "    n_jobs: int, optional\n",
    "        Number of parallel jobs to run.\n",
    "\n",
    "    check_input: boolean, optional\n",
    "        If False, the input arrays X and dictionary will not be checked.\n",
    "\n",
    "    verbose : int, optional\n",
    "        Controls the verbosity; the higher, the more messages. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    code: array of shape (n_samples, n_components)\n",
    "        The sparse codes\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.linear_model.lars_path\n",
    "    sklearn.linear_model.orthogonal_mp\n",
    "    sklearn.linear_model.Lasso\n",
    "    SparseCoder\n",
    "    \"\"\"\n",
    "    if check_input:\n",
    "        if algorithm == 'lasso_cd':\n",
    "            dictionary = check_array(dictionary, order='C', dtype='float64')\n",
    "            X = check_array(X, order='C', dtype='float64')\n",
    "        else:\n",
    "            dictionary = check_array(dictionary)\n",
    "            X = check_array(X)\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    n_components = dictionary.shape[0]\n",
    "\n",
    "    if gram is None and algorithm != 'threshold':\n",
    "        gram = np.dot(dictionary, dictionary.T)\n",
    "\n",
    "    if cov is None and algorithm != 'lasso_cd':\n",
    "        copy_cov = False\n",
    "        cov = np.dot(dictionary, X.T)\n",
    "\n",
    "    if algorithm in ('lars', 'omp'):\n",
    "        regularization = n_nonzero_coefs\n",
    "        if regularization is None:\n",
    "            regularization = min(max(n_features / 10, 1), n_components)\n",
    "    else:\n",
    "        regularization = alpha\n",
    "        if regularization is None:\n",
    "            regularization = 1.\n",
    "\n",
    "    if n_jobs == 1 or algorithm == 'threshold':\n",
    "        code, code_path = _sparse_encode(X,\n",
    "                              dictionary, gram, cov=cov,\n",
    "                              algorithm=algorithm,\n",
    "                              regularization=regularization, copy_cov=copy_cov,\n",
    "                              init=init,\n",
    "                              max_iter=max_iter,\n",
    "                              check_input=False,\n",
    "                              verbose=verbose)\n",
    "        # This ensure that dimensionality of code is always 2,\n",
    "        # consistant with the case n_jobs > 1\n",
    "        if code.ndim == 1:\n",
    "            code = code[np.newaxis, :]\n",
    "        return code, code_path\n",
    "\n",
    "    # Enter parallel code block\n",
    "    code = np.empty((n_samples, n_components))\n",
    "    slices = list(gen_even_slices(n_samples, _get_n_jobs(n_jobs)))\n",
    "\n",
    "    code_views = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
    "        delayed(_sparse_encode)(\n",
    "            X[this_slice], dictionary, gram,\n",
    "            cov[:, this_slice] if cov is not None else None,\n",
    "            algorithm,\n",
    "            regularization=regularization, copy_cov=copy_cov,\n",
    "            init=init[this_slice] if init is not None else None,\n",
    "            max_iter=max_iter,\n",
    "            check_input=False)\n",
    "        for this_slice in slices)\n",
    "    for this_slice, this_view in zip(slices, code_views):\n",
    "        code[this_slice] = this_view\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.826e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.732e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.840e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.380e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.225e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.853e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.172e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.402e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.451e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.965e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.290e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.725e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.578e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.532e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.268e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.532e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.117e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.837e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.908e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.088e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.178e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.013e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.829e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.397e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 9.657e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.546e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 9.657e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.564e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 9.125e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.655e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.476e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.649e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.179e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.742e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.053e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.742e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.737e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 8.878e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.660e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.970e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.929e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.474e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.771e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.971e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.262e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 9.125e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.831e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.290e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.197e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.268e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.105e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.532e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.659e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.573e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.094e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.450e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.992e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.450e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.767e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.998e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.187e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.648e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.723e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.308e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 9.125e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.134e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.625e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.664e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=9.623e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.268e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.539e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.800e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.820e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.268e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.231e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.268e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.139e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.971e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.006e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.976e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.555e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.012e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.760e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.268e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.633e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.511e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 9.125e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.951e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.089e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.830e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.581e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.748e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.235e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.884e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.290e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.867e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.971e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.615e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.797e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.300e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.420e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.066e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.015e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.072e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.663e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.606e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.235e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.318e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.235e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.134e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.451e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.697e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.440e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.911e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.664e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.335e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=9.804e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.268e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.552e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.666e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.425e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.666e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.841e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.319e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.290e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.050e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.290e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.223e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.883e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.162e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.537e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.109e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.172e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.410e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.268e-09\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.331e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=7.172e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.771e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.502e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.054e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.909e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.117e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.699e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.224e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.392e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.156e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.268e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.708e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.738e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.490e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.738e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.278e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.424e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.568e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.046e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.332e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.947e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.356e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.112e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.451e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.942e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.487e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 9.884e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.474e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.885e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.619e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.885e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.474e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.290e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.357e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.650e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.000e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.686e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.074e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.625e-08\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# using Sparse coder from sklearn\n",
    "from sklearn.decomposition import SparseCoder\n",
    "import sklearn\n",
    "\n",
    "#lars_model = cust_sparse_encode(X.T, dictionary=D.T, max_iter=step, algorithm='lars', n_nonzero_coefs=num_steps)\n",
    "\n",
    "lasso_val_trace = []\n",
    "\n",
    "code, code_path = sparse_encode(X.T, dictionary=D.T, max_iter=step, algorithm='lars', n_nonzero_coefs=num_steps)\n",
    "for step in range(num_steps):\n",
    "    # transform everything for sklearn, note that frobenius norm stays the same\n",
    "    lasso_R = code.T\n",
    "    obj_val = np.linalg.norm(X - np.dot(D, lasso_R), 'fro')\n",
    "    lasso_val_trace.append(obj_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAKPCAYAAACVYWyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJklQZQ6kkSZIkqTL/AboWEBrYCBCVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117efbba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(np.arange(1, 1+len(val_trace)), val_trace, label='greedy supermodular minimization')\n",
    "plt.plot(np.array([-1, 1+len(val_trace)]), lasso_val_trace[:2], label='converged LARS')\n",
    "plt.title('Sparse Multiple Linear Regression \\nw. $X \\in \\mathbb{R}^{20 \\\\times 35},\\\\; \\mathcal{D} \\in \\mathbb{R}^{20 \\\\times 27}$')\n",
    "plt.ylabel('Frobenius norm $\\|X \\ -\\mathcal{D}\\mathcal{R}\\|_F^2$')\n",
    "plt.xlabel('number of steps')\n",
    "plt.xlim(0, len(val_trace))\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=10, hspace=10)\n",
    "\n",
    "plt.savefig('sparse_example.png', dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
